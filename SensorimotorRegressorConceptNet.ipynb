{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SensorimotorClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO3KQmPVGn5g0XLLC9W1+js",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnusser/SensorimotorClassifier/blob/master/SensorimotorRegressorConceptNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xygc7FGSAs8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "67ac11c2-67b3-4c36-b2ac-835083f27bf1"
      },
      "source": [
        "!pip install regressors"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regressors\n",
            "  Downloading https://files.pythonhosted.org/packages/80/5d/bacfcf2b3865305156e2507ed9a968cb6c7f326cad1d1720e60f80d02797/regressors-0.0.3.tar.gz\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from regressors) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from regressors) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from regressors) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from regressors) (0.22.2.post1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from regressors) (0.10.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from regressors) (0.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from regressors) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->regressors) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->regressors) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->regressors) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->regressors) (1.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->regressors) (0.16.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.6.1->regressors) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->regressors) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->regressors) (1.15.0)\n",
            "Building wheels for collected packages: regressors\n",
            "  Building wheel for regressors (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regressors: filename=regressors-0.0.3-py2.py3-none-any.whl size=12374 sha256=8c0aca414c6ffbbe6629a546fbb25928c52fe12de4d331583fcde1c3b85c930c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/89/fc/7867f77234d0033395f7ad9814f245b337139acaa06b085aa2\n",
            "Successfully built regressors\n",
            "Installing collected packages: regressors\n",
            "Successfully installed regressors-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rGlkkN8Dyaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from regressors import stats\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqvt_FxTI3M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_to_dict(file_path):\n",
        "    \"\"\"\n",
        "    Creates hashmap with word as key and concept vector as value\n",
        "    :param file_path: path to the conceptnet dictionary file\n",
        "    :return: hashmap of word and vectors\n",
        "    \"\"\"\n",
        "    concept_hash = {}\n",
        "    with open(file_path, encoding=\"utf8\") as f:\n",
        "        text = f.readlines()[1:]\n",
        "        for line in text:\n",
        "            first_item = line.split(\" \").__getitem__(0)\n",
        "            concept_hash[first_item] = line\n",
        "    f.close()\n",
        "    return concept_hash\n",
        "\n",
        "def find_word(embedding, word, dictionary, mode=None):\n",
        "    \"\"\"\n",
        "    Finds embedding vector for a word in the conceptnet hashmap\n",
        "    :param word: input word to analyze\n",
        "    :param concept_hash: hashmap of word and conceptnet vector\n",
        "    :return: returns the appropriate vector or none if its not in the hashmap\n",
        "    \"\"\"\n",
        "    if embedding == \"conceptnet\":\n",
        "      if word in dictionary.keys():\n",
        "          vector = dictionary[word].split(\" \")[1:]\n",
        "          vector = [float(i) for i in vector]\n",
        "      else:\n",
        "          vector = []\n",
        "    if embedding == \"bert\":\n",
        "      bert_vec = bert_embedding([word])[0][1]\n",
        "      if mode == \"add\":\n",
        "        vector = np.asarray([sum(x) for x in zip(*bert_vec)])\n",
        "    return vector\n",
        "\n",
        "def from_np_array(array_string):\n",
        "    \"\"\"\n",
        "    Converts string array from imported csv to an actual\n",
        "    numpy array\n",
        "    :array_string input string which can be represented as np array\n",
        "    \"\"\"\n",
        "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
        "    return np.array(ast.literal_eval(array_string))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Vz2yaGDnHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "ae8bc0a1-39cd-496b-8727-c03d46d9944f"
      },
      "source": [
        "# Sensorimotor Dataset\n",
        "!wget -O \"data.csv\" \"https://osf.io/48wsc/download\"\n",
        "\n",
        "# ConceptNet Word Embeddings\n",
        "!wget https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-en-19.08.txt.gz"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-31 14:55:43--  https://osf.io/48wsc/download\n",
            "Resolving osf.io (osf.io)... 35.190.84.173\n",
            "Connecting to osf.io (osf.io)|35.190.84.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://files.de-1.osf.io/v1/resources/rwhs6/providers/osfstorage/5cc2d6441906ec0017056ba8?action=download&direct&version=1 [following]\n",
            "--2020-08-31 14:55:43--  https://files.de-1.osf.io/v1/resources/rwhs6/providers/osfstorage/5cc2d6441906ec0017056ba8?action=download&direct&version=1\n",
            "Resolving files.de-1.osf.io (files.de-1.osf.io)... 35.186.249.111\n",
            "Connecting to files.de-1.osf.io (files.de-1.osf.io)|35.186.249.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17196336 (16M) [text/csv]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "data.csv            100%[===================>]  16.40M  8.95MB/s    in 1.8s    \n",
            "\n",
            "2020-08-31 14:55:48 (8.95 MB/s) - ‘data.csv’ saved [17196336/17196336]\n",
            "\n",
            "--2020-08-31 14:55:48--  https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-en-19.08.txt.gz\n",
            "Resolving conceptnet.s3.amazonaws.com (conceptnet.s3.amazonaws.com)... 52.216.141.108\n",
            "Connecting to conceptnet.s3.amazonaws.com (conceptnet.s3.amazonaws.com)|52.216.141.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 325403502 (310M) [application/x-gzip]\n",
            "Saving to: ‘numberbatch-en-19.08.txt.gz.2’\n",
            "\n",
            "numberbatch-en-19.0 100%[===================>] 310.33M  42.5MB/s    in 7.8s    \n",
            "\n",
            "2020-08-31 14:55:57 (39.9 MB/s) - ‘numberbatch-en-19.08.txt.gz.2’ saved [325403502/325403502]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NQkaCtqIqdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with gzip.open(\"numberbatch-en-19.08.txt.gz\",'rb') as f_in:\n",
        "    with open('numberbatch-en.txt','wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "concept_hash = parse_to_dict(\"numberbatch-en.txt\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfnqBbAyD8-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7353df50-8521-49f3-f97d-ff2b4b7cee56"
      },
      "source": [
        "df = pd.read_csv(\"data.csv\", usecols=[\"Word\", \"Auditory.mean\", \"Gustatory.mean\", \"Haptic.mean\", \"Interoceptive.mean\", \"Olfactory.mean\", \"Visual.mean\"])\n",
        "df.columns = [\"word\", \"auditory\", \"gustatory\", \"haptic\", \"interoceptive\", \"olfactory\", \"visual\"]\n",
        "df[\"word\"] = df[\"word\"].str.lower()\n",
        "df['word'] = df['word'].str.replace(' ','_')\n",
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>auditory</th>\n",
              "      <th>gustatory</th>\n",
              "      <th>haptic</th>\n",
              "      <th>interoceptive</th>\n",
              "      <th>olfactory</th>\n",
              "      <th>visual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>2.214286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a_cappella</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aardvark</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>4.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aback</td>\n",
              "      <td>1.294118</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>1.352941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abacus</td>\n",
              "      <td>1.555556</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>3.722222</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>3.944444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         word  auditory  gustatory  ...  interoceptive  olfactory    visual\n",
              "0           a  2.214286   0.000000  ...       0.000000   0.000000  2.428571\n",
              "1  a_cappella  4.333333   0.000000  ...       0.722222   0.000000  1.666667\n",
              "2    aardvark  1.625000   0.562500  ...       0.062500   1.250000  4.125000\n",
              "3       aback  1.294118   0.058824  ...       1.352941   0.000000  2.823529\n",
              "4      abacus  1.555556   0.166667  ...       0.277778   0.111111  3.944444\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KXXMl6Qsmd3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "721ce04d-8d8a-4dfa-93a3-7edb7c3f51e1"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>auditory</th>\n",
              "      <th>gustatory</th>\n",
              "      <th>haptic</th>\n",
              "      <th>interoceptive</th>\n",
              "      <th>olfactory</th>\n",
              "      <th>visual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.513996</td>\n",
              "      <td>0.323886</td>\n",
              "      <td>1.074025</td>\n",
              "      <td>1.032225</td>\n",
              "      <td>0.389891</td>\n",
              "      <td>2.897181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.990793</td>\n",
              "      <td>0.696873</td>\n",
              "      <td>0.934217</td>\n",
              "      <td>0.880474</td>\n",
              "      <td>0.619021</td>\n",
              "      <td>0.902461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>2.263158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.384615</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>2.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.117647</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.562500</td>\n",
              "      <td>1.444444</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>3.588235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.944444</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           auditory     gustatory  ...     olfactory        visual\n",
              "count  39707.000000  39707.000000  ...  39707.000000  39707.000000\n",
              "mean       1.513996      0.323886  ...      0.389891      2.897181\n",
              "std        0.990793      0.696873  ...      0.619021      0.902461\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.733333      0.000000  ...      0.052632      2.263158\n",
              "50%        1.384615      0.117647  ...      0.187500      2.937500\n",
              "75%        2.117647      0.300000  ...      0.437500      3.588235\n",
              "max        5.000000      5.000000  ...      5.000000      5.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yey5VZaAJEAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "77635a20-6844-4b77-9457-d1515eb43f8c"
      },
      "source": [
        "vecs = []\n",
        "df[\"max_val\"] = df.iloc[:,1:7].idxmax(axis=1)\n",
        "for index, row in df.iterrows():\n",
        "    word_vec = find_word(embedding=\"conceptnet\", word=row['word'], dictionary=concept_hash)\n",
        "    if word_vec == []:\n",
        "        df.drop(index, inplace=True)\n",
        "    else:\n",
        "        vecs.append(word_vec)\n",
        "df[\"vec\"] = vecs\n",
        "df.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>auditory</th>\n",
              "      <th>gustatory</th>\n",
              "      <th>haptic</th>\n",
              "      <th>interoceptive</th>\n",
              "      <th>olfactory</th>\n",
              "      <th>visual</th>\n",
              "      <th>max_val</th>\n",
              "      <th>vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>2.214286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.1011, -0.0806, -0.0092, 0.0901, -0.0323, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aardvark</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>4.125000</td>\n",
              "      <td>visual</td>\n",
              "      <td>[0.0341, 0.0697, 0.0826, -0.0504, -0.1586, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aback</td>\n",
              "      <td>1.294118</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>1.352941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.823529</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.0821, -0.0935, 0.0306, -0.0153, 0.0239, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abacus</td>\n",
              "      <td>1.555556</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>3.722222</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>3.944444</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.0015, 0.0511, -0.0005, 0.0978, -0.1432, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>abandon</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>2.117647</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>2.176471</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.1269, -0.1875, -0.0127, -0.0012, 0.1389, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       word  ...                                                vec\n",
              "0         a  ...  [-0.1011, -0.0806, -0.0092, 0.0901, -0.0323, -...\n",
              "2  aardvark  ...  [0.0341, 0.0697, 0.0826, -0.0504, -0.1586, 0.0...\n",
              "3     aback  ...  [-0.0821, -0.0935, 0.0306, -0.0153, 0.0239, -0...\n",
              "4    abacus  ...  [-0.0015, 0.0511, -0.0005, 0.0978, -0.1432, -0...\n",
              "5   abandon  ...  [-0.1269, -0.1875, -0.0127, -0.0012, 0.1389, 0...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2gfFWxPBtk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "24e43cf9-43a2-4e8a-865e-dc7444af0bd3"
      },
      "source": [
        " X_train, X_test, y_train, y_test = train_test_split(np.stack(df.vec, axis=0), df, test_size=0.2, random_state=43)\n",
        " print(X_train.shape)\n",
        " print(X_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(31097, 300)\n",
            "(7775, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qli_WyhlOFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "178a6c9e-76ae-4a77-cdbb-134722b182ff"
      },
      "source": [
        "y_train"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>auditory</th>\n",
              "      <th>gustatory</th>\n",
              "      <th>haptic</th>\n",
              "      <th>interoceptive</th>\n",
              "      <th>olfactory</th>\n",
              "      <th>visual</th>\n",
              "      <th>max_val</th>\n",
              "      <th>vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6760</th>\n",
              "      <td>consensually</td>\n",
              "      <td>3.388889</td>\n",
              "      <td>0.055556</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.833333</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>2.666667</td>\n",
              "      <td>auditory</td>\n",
              "      <td>[-0.0683, -0.0763, -0.1048, -0.1125, 0.0147, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6695</th>\n",
              "      <td>congruity</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>2.833333</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.1026, -0.0209, -0.2714, -0.1176, -0.0643, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37796</th>\n",
              "      <td>upward</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.500000</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.1331, -0.0231, 0.0541, 0.1195, 0.0225, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19522</th>\n",
              "      <td>laserjet</td>\n",
              "      <td>1.812500</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>1.875000</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>3.937500</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.0523, 0.0875, -0.0239, 0.1671, -0.037, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34539</th>\n",
              "      <td>thermoelectric</td>\n",
              "      <td>1.083333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.166667</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.0136, 0.1516, -0.086, 0.1359, 0.026, -0.04...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5393</th>\n",
              "      <td>choker</td>\n",
              "      <td>0.973684</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>2.526316</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.105263</td>\n",
              "      <td>3.605263</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.0245, 0.0319, 0.1744, 0.0381, -0.0705, -0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25800</th>\n",
              "      <td>polytechnics</td>\n",
              "      <td>1.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>visual</td>\n",
              "      <td>[0.0297, 0.0847, -0.1461, 0.0394, -0.1432, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18890</th>\n",
              "      <td>jeerer</td>\n",
              "      <td>3.571429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.714286</td>\n",
              "      <td>auditory</td>\n",
              "      <td>[-0.0356, -0.1139, 0.1241, -0.2576, -0.0161, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20241</th>\n",
              "      <td>logroller</td>\n",
              "      <td>1.705882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.352941</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>3.882353</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.1023, -0.0865, -0.0506, 0.0365, -0.0309, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14445</th>\n",
              "      <td>gimpy</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>1.294118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.470588</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.1083, -0.0621, 0.1425, -0.1634, -0.0005, -...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>31097 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 word  ...                                                vec\n",
              "6760     consensually  ...  [-0.0683, -0.0763, -0.1048, -0.1125, 0.0147, 0...\n",
              "6695        congruity  ...  [-0.1026, -0.0209, -0.2714, -0.1176, -0.0643, ...\n",
              "37796          upward  ...  [-0.1331, -0.0231, 0.0541, 0.1195, 0.0225, -0....\n",
              "19522        laserjet  ...  [-0.0523, 0.0875, -0.0239, 0.1671, -0.037, -0....\n",
              "34539  thermoelectric  ...  [-0.0136, 0.1516, -0.086, 0.1359, 0.026, -0.04...\n",
              "...               ...  ...                                                ...\n",
              "5393           choker  ...  [-0.0245, 0.0319, 0.1744, 0.0381, -0.0705, -0....\n",
              "25800    polytechnics  ...  [0.0297, 0.0847, -0.1461, 0.0394, -0.1432, 0.0...\n",
              "18890          jeerer  ...  [-0.0356, -0.1139, 0.1241, -0.2576, -0.0161, -...\n",
              "20241       logroller  ...  [-0.1023, -0.0865, -0.0506, 0.0365, -0.0309, -...\n",
              "14445           gimpy  ...  [-0.1083, -0.0621, 0.1425, -0.1634, -0.0005, -...\n",
              "\n",
              "[31097 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTdpk7IVziap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0b2222af-0041-4892-e74f-906c24a56079"
      },
      "source": [
        "reg_alg = [LinearRegression(), Lasso(alpha=0.00001), ]#GradientBoostingRegressor(verbose=1, n_estimators=350)]\n",
        "scores = []\n",
        "for reg in reg_alg:\n",
        "  mses, maes = [], []\n",
        "  for i in range(6):\n",
        "    model = reg.fit(X_train, y_train.iloc[:,i+1])\n",
        "    mse = mean_squared_error(model.predict(X_test), y_test.iloc[:,i+1], squared=False)\n",
        "    mae = mean_absolute_error(model.predict(X_test), y_test.iloc[:,i+1])\n",
        "    mses.append(mse)\n",
        "    maes.append(mae)\n",
        "  scores.append((np.mean(maes), maes, np.mean(mses), mses))\n",
        "print(scores)"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0.40623758124472237, [0.4955060913099205, 0.2728733188948354, 0.45321892481457304, 0.41374304508500964, 0.2897618528512396, 0.5123222545127564], 0.5369598589840622, [0.6295360433159926, 0.4012604652135086, 0.5931463125225931, 0.5438411742805315, 0.4089642146451524, 0.6450109439265954]), (0.40608554982164885, [0.49549440914939485, 0.2725729582835801, 0.45305227785956137, 0.4136683166190921, 0.2894023627819005, 0.512322974236364], 0.5369349620082696, [0.6295041809708599, 0.401332043962472, 0.5930405460802377, 0.5438331974923788, 0.40886590792591937, 0.64503389561775])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDrBuZDSDUUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To calculate the p-values of beta coefficients: \n",
        "print(\"coef_pval:\\n\", stats.coef_pval(reg, X_test, y_test.haptic))\n",
        "\n",
        "# to print summary table:\n",
        "print(\"\\n=========== SUMMARY ===========\")\n",
        "xlabels = df.columns[1:7]\n",
        "stats.summary(reg, X_test, y_test.haptic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQaWRZnjC4di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " xtrain, xval, ytrain, yval = train_test_split(X_train, y_train, test_size=0.1, random_state=43)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZcb50IaA_wy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "9bd0f67a-5bf6-4483-9e00-53e41babb27e"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(300, activation='relu' ,input_shape=(300,)))\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='linear'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['mse', 'mae'])\n",
        "print(model.summary())\n",
        "filepath=\"weights.best.hdf5\"\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_52 (Dense)             (None, 300)               90300     \n",
            "_________________________________________________________________\n",
            "dropout_31 (Dropout)         (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 32)                9632      \n",
            "_________________________________________________________________\n",
            "dropout_32 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 99,965\n",
            "Trainable params: 99,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRWNB6CoB1OE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "44f3cfd6-a960-4b47-984b-8d841d0ce3f2"
      },
      "source": [
        "mses, maes = [], []\n",
        "for i in range(6):\n",
        "    history = model.fit(xtrain, ytrain.iloc[:,i+1], epochs=50, batch_size=512, validation_data=(xval, yval.iloc[:,i+1]), verbose=1, callbacks=[es_callback])\n",
        "    test_predict = model.predict(X_test).flatten()\n",
        "    mae = mean_absolute_error(test_predict, y_test.iloc[:,i+1])\n",
        "    mse = mean_squared_error(test_predict, y_test.iloc[:,i+1], squared=False)\n",
        "    mses.append(mse)\n",
        "    maes.append(mae)\n",
        "scores.append((np.mean(maes), maes, np.mean(mses), mses))\n",
        "for s in scores:\n",
        "  print(s[0])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.8638 - mse: 1.3246 - mae: 0.8638 - val_loss: 0.5884 - val_mse: 0.6116 - val_mae: 0.5884\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5591 - mse: 0.5357 - mae: 0.5591 - val_loss: 0.4948 - val_mse: 0.4303 - val_mae: 0.4948\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5140 - mse: 0.4583 - mae: 0.5140 - val_loss: 0.4841 - val_mse: 0.4095 - val_mae: 0.4841\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4975 - mse: 0.4322 - mae: 0.4975 - val_loss: 0.4786 - val_mse: 0.4013 - val_mae: 0.4786\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4881 - mse: 0.4190 - mae: 0.4881 - val_loss: 0.4733 - val_mse: 0.3935 - val_mae: 0.4733\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4774 - mse: 0.4030 - mae: 0.4774 - val_loss: 0.4658 - val_mse: 0.3789 - val_mae: 0.4658\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4678 - mse: 0.3883 - mae: 0.4678 - val_loss: 0.4604 - val_mse: 0.3753 - val_mae: 0.4604\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4562 - mse: 0.3739 - mae: 0.4562 - val_loss: 0.4578 - val_mse: 0.3676 - val_mae: 0.4578\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4479 - mse: 0.3605 - mae: 0.4479 - val_loss: 0.4519 - val_mse: 0.3586 - val_mae: 0.4519\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4369 - mse: 0.3443 - mae: 0.4369 - val_loss: 0.4493 - val_mse: 0.3557 - val_mae: 0.4493\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4323 - mse: 0.3376 - mae: 0.4323 - val_loss: 0.4473 - val_mse: 0.3490 - val_mae: 0.4473\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4242 - mse: 0.3262 - mae: 0.4242 - val_loss: 0.4454 - val_mse: 0.3463 - val_mae: 0.4454\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4167 - mse: 0.3142 - mae: 0.4167 - val_loss: 0.4437 - val_mse: 0.3408 - val_mae: 0.4437\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4109 - mse: 0.3060 - mae: 0.4109 - val_loss: 0.4393 - val_mse: 0.3388 - val_mae: 0.4393\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4069 - mse: 0.2998 - mae: 0.4069 - val_loss: 0.4417 - val_mse: 0.3380 - val_mae: 0.4417\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4004 - mse: 0.2923 - mae: 0.4004 - val_loss: 0.4421 - val_mse: 0.3405 - val_mae: 0.4421\n",
            "Epoch 17/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3965 - mse: 0.2905 - mae: 0.3965 - val_loss: 0.4420 - val_mse: 0.3412 - val_mae: 0.4420\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4192 - mse: 0.7149 - mae: 0.4192 - val_loss: 0.2899 - val_mse: 0.4961 - val_mae: 0.2899\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2955 - mse: 0.5188 - mae: 0.2955 - val_loss: 0.2863 - val_mse: 0.4926 - val_mae: 0.2863\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2933 - mse: 0.5124 - mae: 0.2933 - val_loss: 0.2834 - val_mse: 0.4857 - val_mae: 0.2834\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2904 - mse: 0.5063 - mae: 0.2904 - val_loss: 0.2810 - val_mse: 0.4785 - val_mae: 0.2810\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2882 - mse: 0.4994 - mae: 0.2882 - val_loss: 0.2778 - val_mse: 0.4731 - val_mae: 0.2778\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2854 - mse: 0.4926 - mae: 0.2854 - val_loss: 0.2758 - val_mse: 0.4668 - val_mae: 0.2758\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2831 - mse: 0.4864 - mae: 0.2831 - val_loss: 0.2743 - val_mse: 0.4607 - val_mae: 0.2743\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2811 - mse: 0.4804 - mae: 0.2811 - val_loss: 0.2723 - val_mse: 0.4545 - val_mae: 0.2723\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2784 - mse: 0.4737 - mae: 0.2784 - val_loss: 0.2715 - val_mse: 0.4487 - val_mae: 0.2715\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2759 - mse: 0.4669 - mae: 0.2759 - val_loss: 0.2689 - val_mse: 0.4437 - val_mae: 0.2689\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2737 - mse: 0.4610 - mae: 0.2737 - val_loss: 0.2683 - val_mse: 0.4382 - val_mae: 0.2683\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2712 - mse: 0.4529 - mae: 0.2712 - val_loss: 0.2670 - val_mse: 0.4300 - val_mae: 0.2670\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2664 - mse: 0.4363 - mae: 0.2664 - val_loss: 0.2625 - val_mse: 0.4053 - val_mae: 0.2625\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2580 - mse: 0.3959 - mae: 0.2580 - val_loss: 0.2524 - val_mse: 0.3524 - val_mae: 0.2524\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2443 - mse: 0.3238 - mae: 0.2443 - val_loss: 0.2338 - val_mse: 0.2500 - val_mae: 0.2338\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2191 - mse: 0.2113 - mae: 0.2191 - val_loss: 0.2048 - val_mse: 0.1434 - val_mae: 0.2048\n",
            "Epoch 17/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2028 - mse: 0.1637 - mae: 0.2028 - val_loss: 0.1961 - val_mse: 0.1224 - val_mae: 0.1961\n",
            "Epoch 18/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1964 - mse: 0.1498 - mae: 0.1964 - val_loss: 0.1923 - val_mse: 0.1155 - val_mae: 0.1923\n",
            "Epoch 19/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1929 - mse: 0.1444 - mae: 0.1929 - val_loss: 0.1930 - val_mse: 0.1160 - val_mae: 0.1930\n",
            "Epoch 20/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1898 - mse: 0.1405 - mae: 0.1898 - val_loss: 0.1925 - val_mse: 0.1158 - val_mae: 0.1925\n",
            "Epoch 21/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1855 - mse: 0.1320 - mae: 0.1855 - val_loss: 0.1927 - val_mse: 0.1127 - val_mae: 0.1927\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.7245 - mse: 1.1317 - mae: 0.7245 - val_loss: 0.6254 - val_mse: 0.7616 - val_mae: 0.6254\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5299 - mse: 0.5509 - mae: 0.5299 - val_loss: 0.4559 - val_mse: 0.3851 - val_mae: 0.4559\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4582 - mse: 0.4074 - mae: 0.4582 - val_loss: 0.4432 - val_mse: 0.3652 - val_mae: 0.4432\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4392 - mse: 0.3787 - mae: 0.4392 - val_loss: 0.4290 - val_mse: 0.3401 - val_mae: 0.4290\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4266 - mse: 0.3619 - mae: 0.4266 - val_loss: 0.4247 - val_mse: 0.3353 - val_mae: 0.4247\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4109 - mse: 0.3350 - mae: 0.4109 - val_loss: 0.4198 - val_mse: 0.3296 - val_mae: 0.4198\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4022 - mse: 0.3232 - mae: 0.4022 - val_loss: 0.4190 - val_mse: 0.3311 - val_mae: 0.4190\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3894 - mse: 0.3024 - mae: 0.3894 - val_loss: 0.4113 - val_mse: 0.3139 - val_mae: 0.4113\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.3805 - mse: 0.2898 - mae: 0.3805 - val_loss: 0.4098 - val_mse: 0.3110 - val_mae: 0.4098\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3730 - mse: 0.2798 - mae: 0.3730 - val_loss: 0.4084 - val_mse: 0.3108 - val_mae: 0.4084\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3645 - mse: 0.2677 - mae: 0.3645 - val_loss: 0.4047 - val_mse: 0.3043 - val_mae: 0.4047\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3540 - mse: 0.2543 - mae: 0.3540 - val_loss: 0.4031 - val_mse: 0.3047 - val_mae: 0.4031\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3476 - mse: 0.2461 - mae: 0.3476 - val_loss: 0.4021 - val_mse: 0.3004 - val_mae: 0.4021\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3378 - mse: 0.2319 - mae: 0.3378 - val_loss: 0.3996 - val_mse: 0.2967 - val_mae: 0.3996\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3332 - mse: 0.2262 - mae: 0.3332 - val_loss: 0.4006 - val_mse: 0.2983 - val_mae: 0.4006\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3279 - mse: 0.2173 - mae: 0.3279 - val_loss: 0.4037 - val_mse: 0.3044 - val_mae: 0.4037\n",
            "Epoch 17/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3196 - mse: 0.2090 - mae: 0.3196 - val_loss: 0.4011 - val_mse: 0.2955 - val_mae: 0.4011\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.6603 - mse: 0.8542 - mae: 0.6603 - val_loss: 0.4547 - val_mse: 0.3972 - val_mae: 0.4547\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4241 - mse: 0.3468 - mae: 0.4241 - val_loss: 0.3852 - val_mse: 0.2744 - val_mae: 0.3852\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3900 - mse: 0.2902 - mae: 0.3900 - val_loss: 0.3758 - val_mse: 0.2597 - val_mae: 0.3758\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3746 - mse: 0.2710 - mae: 0.3746 - val_loss: 0.3736 - val_mse: 0.2615 - val_mae: 0.3736\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3620 - mse: 0.2555 - mae: 0.3620 - val_loss: 0.3682 - val_mse: 0.2544 - val_mae: 0.3682\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3524 - mse: 0.2419 - mae: 0.3524 - val_loss: 0.3656 - val_mse: 0.2496 - val_mae: 0.3656\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3442 - mse: 0.2326 - mae: 0.3442 - val_loss: 0.3657 - val_mse: 0.2469 - val_mae: 0.3657\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3382 - mse: 0.2261 - mae: 0.3382 - val_loss: 0.3628 - val_mse: 0.2454 - val_mae: 0.3628\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3305 - mse: 0.2160 - mae: 0.3305 - val_loss: 0.3608 - val_mse: 0.2409 - val_mae: 0.3608\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3237 - mse: 0.2074 - mae: 0.3237 - val_loss: 0.3613 - val_mse: 0.2441 - val_mae: 0.3613\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3185 - mse: 0.2015 - mae: 0.3185 - val_loss: 0.3610 - val_mse: 0.2394 - val_mae: 0.3610\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.3123 - mse: 0.1958 - mae: 0.3123 - val_loss: 0.3584 - val_mse: 0.2384 - val_mae: 0.3584\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3086 - mse: 0.1901 - mae: 0.3086 - val_loss: 0.3590 - val_mse: 0.2416 - val_mae: 0.3590\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.3030 - mse: 0.1848 - mae: 0.3030 - val_loss: 0.3590 - val_mse: 0.2401 - val_mae: 0.3590\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2991 - mse: 0.1788 - mae: 0.2991 - val_loss: 0.3582 - val_mse: 0.2400 - val_mae: 0.3582\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2942 - mse: 0.1741 - mae: 0.2942 - val_loss: 0.3610 - val_mse: 0.2433 - val_mae: 0.3610\n",
            "Epoch 17/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2895 - mse: 0.1683 - mae: 0.2895 - val_loss: 0.3595 - val_mse: 0.2386 - val_mae: 0.3595\n",
            "Epoch 18/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2853 - mse: 0.1642 - mae: 0.2853 - val_loss: 0.3589 - val_mse: 0.2391 - val_mae: 0.3589\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4017 - mse: 0.4938 - mae: 0.4017 - val_loss: 0.3178 - val_mse: 0.3699 - val_mae: 0.3178\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2930 - mse: 0.3119 - mae: 0.2930 - val_loss: 0.2971 - val_mse: 0.3064 - val_mae: 0.2971\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2650 - mse: 0.2379 - mae: 0.2650 - val_loss: 0.2668 - val_mse: 0.2213 - val_mae: 0.2668\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2457 - mse: 0.1968 - mae: 0.2457 - val_loss: 0.2572 - val_mse: 0.1914 - val_mae: 0.2572\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2336 - mse: 0.1664 - mae: 0.2336 - val_loss: 0.2465 - val_mse: 0.1651 - val_mae: 0.2465\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2242 - mse: 0.1468 - mae: 0.2242 - val_loss: 0.2400 - val_mse: 0.1531 - val_mae: 0.2400\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2159 - mse: 0.1315 - mae: 0.2159 - val_loss: 0.2382 - val_mse: 0.1499 - val_mae: 0.2382\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2125 - mse: 0.1291 - mae: 0.2125 - val_loss: 0.2345 - val_mse: 0.1420 - val_mae: 0.2345\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2081 - mse: 0.1216 - mae: 0.2081 - val_loss: 0.2328 - val_mse: 0.1406 - val_mae: 0.2328\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.2030 - mse: 0.1153 - mae: 0.2030 - val_loss: 0.2318 - val_mse: 0.1415 - val_mae: 0.2318\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1983 - mse: 0.1108 - mae: 0.1983 - val_loss: 0.2310 - val_mse: 0.1394 - val_mae: 0.2310\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1951 - mse: 0.1066 - mae: 0.1951 - val_loss: 0.2308 - val_mse: 0.1379 - val_mae: 0.2308\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1913 - mse: 0.1032 - mae: 0.1913 - val_loss: 0.2302 - val_mse: 0.1368 - val_mae: 0.2302\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1884 - mse: 0.1003 - mae: 0.1884 - val_loss: 0.2303 - val_mse: 0.1351 - val_mae: 0.2303\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1847 - mse: 0.0948 - mae: 0.1847 - val_loss: 0.2299 - val_mse: 0.1350 - val_mae: 0.2299\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1830 - mse: 0.0929 - mae: 0.1830 - val_loss: 0.2299 - val_mse: 0.1376 - val_mae: 0.2299\n",
            "Epoch 17/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1805 - mse: 0.0912 - mae: 0.1805 - val_loss: 0.2286 - val_mse: 0.1349 - val_mae: 0.2286\n",
            "Epoch 18/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1768 - mse: 0.0875 - mae: 0.1768 - val_loss: 0.2285 - val_mse: 0.1323 - val_mae: 0.2285\n",
            "Epoch 19/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1758 - mse: 0.0867 - mae: 0.1758 - val_loss: 0.2279 - val_mse: 0.1331 - val_mae: 0.2279\n",
            "Epoch 20/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1721 - mse: 0.0825 - mae: 0.1721 - val_loss: 0.2275 - val_mse: 0.1295 - val_mae: 0.2275\n",
            "Epoch 21/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1691 - mse: 0.0798 - mae: 0.1691 - val_loss: 0.2290 - val_mse: 0.1346 - val_mae: 0.2290\n",
            "Epoch 22/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1679 - mse: 0.0780 - mae: 0.1679 - val_loss: 0.2280 - val_mse: 0.1315 - val_mae: 0.2280\n",
            "Epoch 23/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.1638 - mse: 0.0744 - mae: 0.1638 - val_loss: 0.2289 - val_mse: 0.1341 - val_mae: 0.2289\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 1.2812 - mse: 2.7218 - mae: 1.2812 - val_loss: 0.5603 - val_mse: 0.4966 - val_mae: 0.5603\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5983 - mse: 0.5685 - mae: 0.5983 - val_loss: 0.5157 - val_mse: 0.4174 - val_mae: 0.5157\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5624 - mse: 0.5018 - mae: 0.5624 - val_loss: 0.5015 - val_mse: 0.3960 - val_mae: 0.5015\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5440 - mse: 0.4717 - mae: 0.5440 - val_loss: 0.4936 - val_mse: 0.3840 - val_mae: 0.4936\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5259 - mse: 0.4403 - mae: 0.5259 - val_loss: 0.4861 - val_mse: 0.3731 - val_mae: 0.4861\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5147 - mse: 0.4236 - mae: 0.5147 - val_loss: 0.4804 - val_mse: 0.3652 - val_mae: 0.4804\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.5012 - mse: 0.4041 - mae: 0.5012 - val_loss: 0.4789 - val_mse: 0.3634 - val_mae: 0.4789\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4934 - mse: 0.3917 - mae: 0.4934 - val_loss: 0.4788 - val_mse: 0.3615 - val_mae: 0.4788\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4858 - mse: 0.3809 - mae: 0.4858 - val_loss: 0.4784 - val_mse: 0.3599 - val_mae: 0.4784\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 1s 13ms/step - loss: 0.4768 - mse: 0.3674 - mae: 0.4768 - val_loss: 0.4745 - val_mse: 0.3547 - val_mae: 0.4745\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.4718 - mse: 0.3598 - mae: 0.4718 - val_loss: 0.4730 - val_mse: 0.3529 - val_mae: 0.4730\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.4672 - mse: 0.3535 - mae: 0.4672 - val_loss: 0.4737 - val_mse: 0.3521 - val_mae: 0.4737\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4589 - mse: 0.3401 - mae: 0.4589 - val_loss: 0.4758 - val_mse: 0.3543 - val_mae: 0.4758\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4522 - mse: 0.3334 - mae: 0.4522 - val_loss: 0.4723 - val_mse: 0.3503 - val_mae: 0.4723\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4471 - mse: 0.3240 - mae: 0.4471 - val_loss: 0.4726 - val_mse: 0.3514 - val_mae: 0.4726\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4424 - mse: 0.3179 - mae: 0.4424 - val_loss: 0.4713 - val_mse: 0.3504 - val_mae: 0.4713\n",
            "Epoch 17/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4383 - mse: 0.3133 - mae: 0.4383 - val_loss: 0.4754 - val_mse: 0.3537 - val_mae: 0.4754\n",
            "Epoch 18/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4357 - mse: 0.3096 - mae: 0.4357 - val_loss: 0.4711 - val_mse: 0.3501 - val_mae: 0.4711\n",
            "Epoch 19/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4262 - mse: 0.2979 - mae: 0.4262 - val_loss: 0.4703 - val_mse: 0.3482 - val_mae: 0.4703\n",
            "Epoch 20/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4236 - mse: 0.2947 - mae: 0.4236 - val_loss: 0.4719 - val_mse: 0.3504 - val_mae: 0.4719\n",
            "Epoch 21/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4159 - mse: 0.2850 - mae: 0.4159 - val_loss: 0.4707 - val_mse: 0.3495 - val_mae: 0.4707\n",
            "Epoch 22/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4158 - mse: 0.2858 - mae: 0.4158 - val_loss: 0.4706 - val_mse: 0.3484 - val_mae: 0.4706\n",
            "0.40623758124472237\n",
            "0.40608554982164885\n",
            "0.3447771451405947\n",
            "0.34537545666216823\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trbSLp9_PQmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b1072d91-38c4-430e-8476-168b87db5a1f"
      },
      "source": [
        "for s in scores:\n",
        "  print(s[2])"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5369598589840622\n",
            "0.5369349620082696\n",
            "0.46936029032593546\n",
            "0.47824376907802835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR1D8mHYFrfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "61c9729e-48c9-4a37-9d79-4934abbec959"
      },
      "source": [
        "# Loss plot\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy plot\n",
        "plt.clf()\n",
        "acc_values = history_dict['mse']\n",
        "val_acc_values = history_dict['val_mse']\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}