{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SensorimotorClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8JPkx/H/v+GBnwElV971S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tnusser/SensorimotorClassifier/blob/master/SensorimotorRegressorConceptNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls_lQrrtV6AL",
        "colab_type": "text"
      },
      "source": [
        "## Package Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xygc7FGSAs8U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "4a777be5-43ef-4530-9248-e910cd42457e"
      },
      "source": [
        "!pip install regressors"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting regressors\n",
            "  Downloading https://files.pythonhosted.org/packages/80/5d/bacfcf2b3865305156e2507ed9a968cb6c7f326cad1d1720e60f80d02797/regressors-0.0.3.tar.gz\n",
            "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from regressors) (1.18.5)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from regressors) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from regressors) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from regressors) (0.22.2.post1)\n",
            "Requirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from regressors) (0.10.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from regressors) (0.10.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from regressors) (1.0.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->regressors) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->regressors) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->regressors) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->regressors) (1.2.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.17->regressors) (0.16.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from statsmodels>=0.6.1->regressors) (0.5.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->regressors) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->regressors) (1.15.0)\n",
            "Building wheels for collected packages: regressors\n",
            "  Building wheel for regressors (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regressors: filename=regressors-0.0.3-py2.py3-none-any.whl size=12374 sha256=4170cd4979c6aaf5a9932b5ef309026149980f0531caba2fadacc23ba6eded7c\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/89/fc/7867f77234d0033395f7ad9814f245b337139acaa06b085aa2\n",
            "Successfully built regressors\n",
            "Installing collected packages: regressors\n",
            "Successfully installed regressors-0.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl1XeDOEV9ET",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rGlkkN8Dyaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "\n",
        "import gzip\n",
        "import shutil\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from regressors import stats\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j24wRagFV_Zi",
        "colab_type": "text"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mqvt_FxTI3M2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_to_dict(file_path):\n",
        "    \"\"\"\n",
        "    Creates hashmap with word as key and concept vector as value\n",
        "    :param file_path: path to the conceptnet dictionary file\n",
        "    :return: hashmap of word and vectors\n",
        "    \"\"\"\n",
        "    concept_hash = {}\n",
        "    with open(file_path, encoding=\"utf8\") as f:\n",
        "        text = f.readlines()[1:]\n",
        "        for line in text:\n",
        "            first_item = line.split(\" \").__getitem__(0)\n",
        "            concept_hash[first_item] = line\n",
        "    f.close()\n",
        "    return concept_hash\n",
        "\n",
        "def find_word(embedding, word, dictionary, mode=None):\n",
        "    \"\"\"\n",
        "    Finds embedding vector for a word in the conceptnet hashmap\n",
        "    :param word: input word to analyze\n",
        "    :param concept_hash: hashmap of word and conceptnet vector\n",
        "    :return: returns the appropriate vector or none if its not in the hashmap\n",
        "    \"\"\"\n",
        "    if embedding == \"conceptnet\":\n",
        "      if word in dictionary.keys():\n",
        "          vector = dictionary[word].split(\" \")[1:]\n",
        "          vector = [float(i) for i in vector]\n",
        "      else:\n",
        "          vector = []\n",
        "    if embedding == \"bert\":\n",
        "      bert_vec = bert_embedding([word])[0][1]\n",
        "      if mode == \"add\":\n",
        "        vector = np.asarray([sum(x) for x in zip(*bert_vec)])\n",
        "    return vector\n",
        "\n",
        "def from_np_array(array_string):\n",
        "    \"\"\"\n",
        "    Converts string array from imported csv to an actual\n",
        "    numpy array\n",
        "    :array_string input string which can be represented as np array\n",
        "    \"\"\"\n",
        "    array_string = ','.join(array_string.replace('[ ', '[').split())\n",
        "    return np.array(ast.literal_eval(array_string))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KeZLUtkWBBl",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_Vz2yaGDnHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "549c9458-3ccd-4f3a-f3ca-98b75846b82b"
      },
      "source": [
        "# Sensorimotor Dataset\n",
        "!wget -O \"data.csv\" \"https://osf.io/48wsc/download\"\n",
        "\n",
        "# ConceptNet Word Embeddings\n",
        "!wget https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-en-19.08.txt.gz"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-01 15:40:37--  https://osf.io/48wsc/download\n",
            "Resolving osf.io (osf.io)... 35.190.84.173\n",
            "Connecting to osf.io (osf.io)|35.190.84.173|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://files.de-1.osf.io/v1/resources/rwhs6/providers/osfstorage/5cc2d6441906ec0017056ba8?action=download&direct&version=1 [following]\n",
            "--2020-09-01 15:40:38--  https://files.de-1.osf.io/v1/resources/rwhs6/providers/osfstorage/5cc2d6441906ec0017056ba8?action=download&direct&version=1\n",
            "Resolving files.de-1.osf.io (files.de-1.osf.io)... 35.186.249.111\n",
            "Connecting to files.de-1.osf.io (files.de-1.osf.io)|35.186.249.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17196336 (16M) [text/csv]\n",
            "Saving to: ‘data.csv’\n",
            "\n",
            "data.csv            100%[===================>]  16.40M  4.98MB/s    in 3.3s    \n",
            "\n",
            "2020-09-01 15:40:44 (4.98 MB/s) - ‘data.csv’ saved [17196336/17196336]\n",
            "\n",
            "--2020-09-01 15:40:45--  https://conceptnet.s3.amazonaws.com/downloads/2019/numberbatch/numberbatch-en-19.08.txt.gz\n",
            "Resolving conceptnet.s3.amazonaws.com (conceptnet.s3.amazonaws.com)... 52.216.104.243\n",
            "Connecting to conceptnet.s3.amazonaws.com (conceptnet.s3.amazonaws.com)|52.216.104.243|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 325403502 (310M) [application/x-gzip]\n",
            "Saving to: ‘numberbatch-en-19.08.txt.gz’\n",
            "\n",
            "numberbatch-en-19.0 100%[===================>] 310.33M  14.1MB/s    in 22s     \n",
            "\n",
            "2020-09-01 15:41:08 (14.0 MB/s) - ‘numberbatch-en-19.08.txt.gz’ saved [325403502/325403502]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NQkaCtqIqdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with gzip.open(\"numberbatch-en-19.08.txt.gz\",'rb') as f_in:\n",
        "    with open('numberbatch-en.txt','wb') as f_out:\n",
        "        shutil.copyfileobj(f_in, f_out)\n",
        "concept_hash = parse_to_dict(\"numberbatch-en.txt\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfnqBbAyD8-d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "bc7cd35b-a179-4cae-a4d7-0aec4af68503"
      },
      "source": [
        "df = pd.read_csv(\"data.csv\", usecols=[\"Word\", \"Auditory.mean\", \"Gustatory.mean\", \"Haptic.mean\", \"Interoceptive.mean\", \"Olfactory.mean\", \"Visual.mean\"])\n",
        "df.columns = [\"word\", \"auditory\", \"gustatory\", \"haptic\", \"interoceptive\", \"olfactory\", \"visual\"]\n",
        "df[\"word\"] = df[\"word\"].str.lower()\n",
        "df['word'] = df['word'].str.replace(' ','_')\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>auditory</th>\n",
              "      <th>gustatory</th>\n",
              "      <th>haptic</th>\n",
              "      <th>interoceptive</th>\n",
              "      <th>olfactory</th>\n",
              "      <th>visual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>2.214286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a_cappella</td>\n",
              "      <td>4.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.666667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aardvark</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>4.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aback</td>\n",
              "      <td>1.294118</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>1.352941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.823529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abacus</td>\n",
              "      <td>1.555556</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>3.722222</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>3.944444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         word  auditory  gustatory  ...  interoceptive  olfactory    visual\n",
              "0           a  2.214286   0.000000  ...       0.000000   0.000000  2.428571\n",
              "1  a_cappella  4.333333   0.000000  ...       0.722222   0.000000  1.666667\n",
              "2    aardvark  1.625000   0.562500  ...       0.062500   1.250000  4.125000\n",
              "3       aback  1.294118   0.058824  ...       1.352941   0.000000  2.823529\n",
              "4      abacus  1.555556   0.166667  ...       0.277778   0.111111  3.944444\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KXXMl6Qsmd3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "c8da28d4-85f0-4ec0-8e85-bfc302cc0368"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>auditory</th>\n",
              "      <th>gustatory</th>\n",
              "      <th>haptic</th>\n",
              "      <th>interoceptive</th>\n",
              "      <th>olfactory</th>\n",
              "      <th>visual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "      <td>39707.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.513996</td>\n",
              "      <td>0.323886</td>\n",
              "      <td>1.074025</td>\n",
              "      <td>1.032225</td>\n",
              "      <td>0.389891</td>\n",
              "      <td>2.897181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.990793</td>\n",
              "      <td>0.696873</td>\n",
              "      <td>0.934217</td>\n",
              "      <td>0.880474</td>\n",
              "      <td>0.619021</td>\n",
              "      <td>0.902461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.363636</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>2.263158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.384615</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>2.937500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.117647</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.562500</td>\n",
              "      <td>1.444444</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>3.588235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.944444</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           auditory     gustatory  ...     olfactory        visual\n",
              "count  39707.000000  39707.000000  ...  39707.000000  39707.000000\n",
              "mean       1.513996      0.323886  ...      0.389891      2.897181\n",
              "std        0.990793      0.696873  ...      0.619021      0.902461\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.733333      0.000000  ...      0.052632      2.263158\n",
              "50%        1.384615      0.117647  ...      0.187500      2.937500\n",
              "75%        2.117647      0.300000  ...      0.437500      3.588235\n",
              "max        5.000000      5.000000  ...      5.000000      5.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yey5VZaAJEAx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "2e48beeb-f7cf-4998-c3c0-51001b0883e4"
      },
      "source": [
        "vecs = []\n",
        "df[\"max_val\"] = df.iloc[:,1:7].idxmax(axis=1)\n",
        "for index, row in df.iterrows():\n",
        "    word_vec = find_word(embedding=\"conceptnet\", word=row['word'], dictionary=concept_hash)\n",
        "    if word_vec == []:\n",
        "        df.drop(index, inplace=True)\n",
        "    else:\n",
        "        vecs.append(word_vec)\n",
        "df[\"vec\"] = vecs\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>auditory</th>\n",
              "      <th>gustatory</th>\n",
              "      <th>haptic</th>\n",
              "      <th>interoceptive</th>\n",
              "      <th>olfactory</th>\n",
              "      <th>visual</th>\n",
              "      <th>max_val</th>\n",
              "      <th>vec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a</td>\n",
              "      <td>2.214286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.428571</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.428571</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.1011, -0.0806, -0.0092, 0.0901, -0.0323, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aardvark</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>1.625000</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>4.125000</td>\n",
              "      <td>visual</td>\n",
              "      <td>[0.0341, 0.0697, 0.0826, -0.0504, -0.1586, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aback</td>\n",
              "      <td>1.294118</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>1.352941</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.823529</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.0821, -0.0935, 0.0306, -0.0153, 0.0239, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abacus</td>\n",
              "      <td>1.555556</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>3.722222</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>3.944444</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.0015, 0.0511, -0.0005, 0.0978, -0.1432, -0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>abandon</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>2.117647</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>2.176471</td>\n",
              "      <td>visual</td>\n",
              "      <td>[-0.1269, -0.1875, -0.0127, -0.0012, 0.1389, 0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       word  ...                                                vec\n",
              "0         a  ...  [-0.1011, -0.0806, -0.0092, 0.0901, -0.0323, -...\n",
              "2  aardvark  ...  [0.0341, 0.0697, 0.0826, -0.0504, -0.1586, 0.0...\n",
              "3     aback  ...  [-0.0821, -0.0935, 0.0306, -0.0153, 0.0239, -0...\n",
              "4    abacus  ...  [-0.0015, 0.0511, -0.0005, 0.0978, -0.1432, -0...\n",
              "5   abandon  ...  [-0.1269, -0.1875, -0.0127, -0.0012, 0.1389, 0...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3NdTsvuVY0m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "cef368d3-c19d-4527-a77c-426178200caf"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>auditory</th>\n",
              "      <th>gustatory</th>\n",
              "      <th>haptic</th>\n",
              "      <th>interoceptive</th>\n",
              "      <th>olfactory</th>\n",
              "      <th>visual</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>38872.000000</td>\n",
              "      <td>38872.000000</td>\n",
              "      <td>38872.000000</td>\n",
              "      <td>38872.000000</td>\n",
              "      <td>38872.000000</td>\n",
              "      <td>38872.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.518045</td>\n",
              "      <td>0.325248</td>\n",
              "      <td>1.074665</td>\n",
              "      <td>1.034313</td>\n",
              "      <td>0.391868</td>\n",
              "      <td>2.900529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.992396</td>\n",
              "      <td>0.699326</td>\n",
              "      <td>0.932906</td>\n",
              "      <td>0.881571</td>\n",
              "      <td>0.621650</td>\n",
              "      <td>0.902145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.368421</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>2.266667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.388889</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>2.941176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2.117647</td>\n",
              "      <td>0.304348</td>\n",
              "      <td>1.562500</td>\n",
              "      <td>1.450000</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>3.588235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>4.944444</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           auditory     gustatory  ...     olfactory        visual\n",
              "count  38872.000000  38872.000000  ...  38872.000000  38872.000000\n",
              "mean       1.518045      0.325248  ...      0.391868      2.900529\n",
              "std        0.992396      0.699326  ...      0.621650      0.902145\n",
              "min        0.000000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.733333      0.000000  ...      0.052632      2.266667\n",
              "50%        1.388889      0.117647  ...      0.187500      2.941176\n",
              "75%        2.117647      0.304348  ...      0.437500      3.588235\n",
              "max        5.000000      5.000000  ...      5.000000      5.000000\n",
              "\n",
              "[8 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ScSO2pVWQ_3",
        "colab_type": "text"
      },
      "source": [
        "## Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1L2gfFWxPBtk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ff777d4c-9436-408c-ab3f-2d9c02c03b30"
      },
      "source": [
        " X_train, X_test, y_train, y_test = train_test_split(np.stack(df.vec, axis=0), df, test_size=0.2, random_state=43)\n",
        " print(X_train.shape)\n",
        " print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(31097, 300)\n",
            "(7775, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eWPBuinWTBX",
        "colab_type": "text"
      },
      "source": [
        "## Regression models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTdpk7IVziap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66c2304a-9f54-4a54-9dde-f51daa56a7ee"
      },
      "source": [
        "reg_alg = [LinearRegression(), Lasso(alpha=0.00001), GradientBoostingRegressor(verbose=1, n_estimators=350)]\n",
        "scores = []\n",
        "for reg in reg_alg:\n",
        "  mses, maes = [], []\n",
        "  for i in range(6):\n",
        "    model = reg.fit(X_train, y_train.iloc[:,i+1])\n",
        "    mse = mean_squared_error(model.predict(X_test), y_test.iloc[:,i+1], squared=False)\n",
        "    mae = mean_absolute_error(model.predict(X_test), y_test.iloc[:,i+1])\n",
        "    mses.append(mse)\n",
        "    maes.append(mae)\n",
        "  scores.append((np.mean(maes), maes, np.mean(mses), mses))\n",
        "print(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.9368           21.79m\n",
            "         2           0.8982           21.67m\n",
            "         3           0.8652           21.60m\n",
            "         4           0.8389           21.50m\n",
            "         5           0.8147           21.47m\n",
            "         6           0.7934           21.42m\n",
            "         7           0.7758           21.39m\n",
            "         8           0.7600           21.32m\n",
            "         9           0.7452           21.24m\n",
            "        10           0.7304           21.18m\n",
            "        20           0.6341           20.46m\n",
            "        30           0.5806           19.77m\n",
            "        40           0.5450           19.13m\n",
            "        50           0.5181           18.48m\n",
            "        60           0.4976           17.84m\n",
            "        70           0.4812           17.22m\n",
            "        80           0.4678           16.61m\n",
            "        90           0.4551           15.98m\n",
            "       100           0.4445           15.36m\n",
            "       200           0.3800            9.21m\n",
            "       300           0.3450            3.07m\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.4387           21.25m\n",
            "         2           0.4051           21.20m\n",
            "         3           0.3765           21.11m\n",
            "         4           0.3513           21.04m\n",
            "         5           0.3302           20.97m\n",
            "         6           0.3109           20.92m\n",
            "         7           0.2940           20.87m\n",
            "         8           0.2797           20.80m\n",
            "         9           0.2677           20.76m\n",
            "        10           0.2557           20.71m\n",
            "        20           0.1951           20.17m\n",
            "        30           0.1724           19.57m\n",
            "        40           0.1613           19.00m\n",
            "        50           0.1542           18.41m\n",
            "        60           0.1486           17.81m\n",
            "        70           0.1438           17.20m\n",
            "        80           0.1397           16.59m\n",
            "        90           0.1359           15.97m\n",
            "       100           0.1327           15.36m\n",
            "       200           0.1112            9.20m\n",
            "       300           0.0977            3.06m\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.8152           21.51m\n",
            "         2           0.7712           21.53m\n",
            "         3           0.7333           21.47m\n",
            "         4           0.7023           21.37m\n",
            "         5           0.6740           21.30m\n",
            "         6           0.6515           21.21m\n",
            "         7           0.6310           21.15m\n",
            "         8           0.6142           21.07m\n",
            "         9           0.5986           21.01m\n",
            "        10           0.5849           20.95m\n",
            "        20           0.5053           20.32m\n",
            "        30           0.4636           19.68m\n",
            "        40           0.4388           19.05m\n",
            "        50           0.4211           18.43m\n",
            "        60           0.4061           17.80m\n",
            "        70           0.3943           17.19m\n",
            "        80           0.3838           16.65m\n",
            "        90           0.3752           16.05m\n",
            "       100           0.3668           15.44m\n",
            "       200           0.3152            9.23m\n",
            "       300           0.2849            3.07m\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.7327           21.61m\n",
            "         2           0.6907           21.52m\n",
            "         3           0.6558           21.44m\n",
            "         4           0.6255           21.40m\n",
            "         5           0.6003           21.41m\n",
            "         6           0.5786           21.39m\n",
            "         7           0.5603           21.34m\n",
            "         8           0.5438           21.33m\n",
            "         9           0.5293           21.28m\n",
            "        10           0.5171           21.23m\n",
            "        20           0.4388           20.64m\n",
            "        30           0.3992           19.97m\n",
            "        40           0.3755           19.30m\n",
            "        50           0.3572           18.65m\n",
            "        60           0.3441           18.02m\n",
            "        70           0.3335           17.37m\n",
            "        80           0.3247           16.72m\n",
            "        90           0.3165           16.09m\n",
            "       100           0.3101           15.45m\n",
            "       200           0.2668            9.23m\n",
            "       300           0.2413            3.07m\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.3587           21.70m\n",
            "         2           0.3387           21.62m\n",
            "         3           0.3209           21.54m\n",
            "         4           0.3046           21.55m\n",
            "         5           0.2912           21.51m\n",
            "         6           0.2798           21.45m\n",
            "         7           0.2710           21.38m\n",
            "         8           0.2623           21.31m\n",
            "         9           0.2546           21.21m\n",
            "        10           0.2477           21.13m\n",
            "        20           0.2095           20.33m\n",
            "        30           0.1927           19.64m\n",
            "        40           0.1815           19.07m\n",
            "        50           0.1731           18.43m\n",
            "        60           0.1661           17.80m\n",
            "        70           0.1607           17.18m\n",
            "        80           0.1563           16.56m\n",
            "        90           0.1521           15.94m\n",
            "       100           0.1484           15.33m\n",
            "       200           0.1252            9.21m\n",
            "       300           0.1113            3.07m\n",
            "      Iter       Train Loss   Remaining Time \n",
            "         1           0.7737           21.50m\n",
            "         2           0.7430           21.44m\n",
            "         3           0.7173           21.36m\n",
            "         4           0.6961           21.31m\n",
            "         5           0.6785           21.28m\n",
            "         6           0.6629           21.23m\n",
            "         7           0.6489           21.16m\n",
            "         8           0.6366           21.08m\n",
            "         9           0.6256           21.04m\n",
            "        10           0.6161           20.97m\n",
            "        20           0.5531           20.48m\n",
            "        30           0.5184           19.80m\n",
            "        40           0.4950           19.19m\n",
            "        50           0.4776           18.58m\n",
            "        60           0.4628           17.98m\n",
            "        70           0.4504           17.35m\n",
            "        80           0.4401           16.73m\n",
            "        90           0.4306           16.10m\n",
            "       100           0.4223           15.48m\n",
            "       200           0.3686            9.23m\n",
            "       300           0.3369            3.07m\n",
            "[(0.40623758124472237, [0.4955060913099205, 0.2728733188948354, 0.45321892481457304, 0.41374304508500964, 0.2897618528512396, 0.5123222545127564], 0.5369598589840622, [0.6295360433159926, 0.4012604652135086, 0.5931463125225931, 0.5438411742805315, 0.4089642146451524, 0.6450109439265954]), (0.40608554982164885, [0.49549440914939485, 0.2725729582835801, 0.45305227785956137, 0.4136683166190921, 0.2894023627819005, 0.512322974236364], 0.5369349620082696, [0.6295041809708599, 0.401332043962472, 0.5930405460802377, 0.5438331974923788, 0.40886590792591937, 0.64503389561775]), (0.3916939717220335, [0.494207643398233, 0.2269546313573126, 0.4487351318991862, 0.4095856709345615, 0.257999890990745, 0.5126808617521629], 0.5321245094627232, [0.6314117950587989, 0.3803651143000292, 0.5940404668724854, 0.5458464039147981, 0.39344885451942196, 0.6476344221108052])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDrBuZDSDUUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To calculate the p-values of beta coefficients: \n",
        "print(\"coef_pval:\\n\", stats.coef_pval(reg, X_test, y_test.haptic))\n",
        "\n",
        "# to print summary table:\n",
        "print(\"\\n=========== SUMMARY ===========\")\n",
        "xlabels = df.columns[1:7]\n",
        "stats.summary(reg, X_test, y_test.haptic)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQaWRZnjC4di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " xtrain, xval, ytrain, yval = train_test_split(X_train, y_train, test_size=0.1, random_state=43)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVO6LjacWVs0",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZcb50IaA_wy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "0ab4b488-f37a-486c-c182-96df86c6b56e"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Dense(300, activation='relu' ,input_shape=(300,)))\n",
        "model.add(keras.layers.Dropout(0.4))\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.2))\n",
        "model.add(layers.Dense(1, activation='linear'))\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['mse', 'mae'])\n",
        "print(model.summary())\n",
        "filepath=\"weights.best.hdf5\"\n",
        "es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 300)               90300     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 32)                9632      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 99,965\n",
            "Trainable params: 99,965\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRWNB6CoB1OE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1176b541-b9d5-4bf2-9433-de76223166ea"
      },
      "source": [
        "mses, maes = [], []\n",
        "for i in range(6):\n",
        "    history = model.fit(xtrain, ytrain.iloc[:,i+1], epochs=50, batch_size=512, validation_data=(xval, yval.iloc[:,i+1]), verbose=1, callbacks=[es_callback])\n",
        "    test_predict = model.predict(X_test).flatten()\n",
        "    mae = mean_absolute_error(test_predict, y_test.iloc[:,i+1])\n",
        "    mse = mean_squared_error(test_predict, y_test.iloc[:,i+1], squared=False)\n",
        "    mses.append(mse)\n",
        "    maes.append(mae)\n",
        "scores.append((np.mean(maes), maes, np.mean(mses), mses))\n",
        "for s in scores:\n",
        "  print(s[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 1.3789 - mse: 1.3789 - mae: 0.9015 - val_loss: 0.5827 - val_mse: 0.5827 - val_mae: 0.6003\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.5400 - mse: 0.5400 - mae: 0.5773 - val_loss: 0.4391 - val_mse: 0.4391 - val_mae: 0.5129\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4712 - mse: 0.4712 - mae: 0.5304 - val_loss: 0.4127 - val_mse: 0.4127 - val_mae: 0.4975\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4433 - mse: 0.4433 - mae: 0.5141 - val_loss: 0.3989 - val_mse: 0.3989 - val_mae: 0.4873\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 11ms/step - loss: 0.4246 - mse: 0.4246 - mae: 0.5015 - val_loss: 0.3891 - val_mse: 0.3891 - val_mae: 0.4806\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 16ms/step - loss: 0.4079 - mse: 0.4079 - mae: 0.4901 - val_loss: 0.3807 - val_mse: 0.3807 - val_mae: 0.4727\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 16ms/step - loss: 0.3923 - mse: 0.3923 - mae: 0.4809 - val_loss: 0.3718 - val_mse: 0.3718 - val_mae: 0.4666\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 18ms/step - loss: 0.3790 - mse: 0.3790 - mae: 0.4716 - val_loss: 0.3602 - val_mse: 0.3602 - val_mae: 0.4620\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.3597 - mse: 0.3597 - mae: 0.4603 - val_loss: 0.3549 - val_mse: 0.3549 - val_mae: 0.4581\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 1s 15ms/step - loss: 0.3448 - mse: 0.3448 - mae: 0.4506 - val_loss: 0.3464 - val_mse: 0.3464 - val_mae: 0.4522\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 14ms/step - loss: 0.3341 - mse: 0.3341 - mae: 0.4432 - val_loss: 0.3458 - val_mse: 0.3458 - val_mae: 0.4505\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 12ms/step - loss: 0.3181 - mse: 0.3181 - mae: 0.4336 - val_loss: 0.3369 - val_mse: 0.3369 - val_mae: 0.4458\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.3116 - mse: 0.3116 - mae: 0.4291 - val_loss: 0.3379 - val_mse: 0.3379 - val_mae: 0.4464\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2998 - mse: 0.2998 - mae: 0.4210 - val_loss: 0.3388 - val_mse: 0.3388 - val_mae: 0.4456\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2922 - mse: 0.2922 - mae: 0.4162 - val_loss: 0.3311 - val_mse: 0.3311 - val_mae: 0.4427\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2881 - mse: 0.2881 - mae: 0.4126 - val_loss: 0.3328 - val_mse: 0.3328 - val_mae: 0.4422\n",
            "Epoch 17/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2797 - mse: 0.2797 - mae: 0.4060 - val_loss: 0.3330 - val_mse: 0.3330 - val_mae: 0.4419\n",
            "Epoch 18/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.2697 - mse: 0.2697 - mae: 0.4001 - val_loss: 0.3311 - val_mse: 0.3311 - val_mae: 0.4408\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6121 - mse: 0.6121 - mae: 0.4233 - val_loss: 0.3205 - val_mse: 0.3205 - val_mae: 0.3026\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2455 - mse: 0.2455 - mae: 0.2699 - val_loss: 0.1325 - val_mse: 0.1325 - val_mae: 0.2135\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1740 - mse: 0.1740 - mae: 0.2263 - val_loss: 0.1203 - val_mse: 0.1203 - val_mae: 0.2078\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.1585 - mse: 0.1585 - mae: 0.2215 - val_loss: 0.1161 - val_mse: 0.1161 - val_mae: 0.2075\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1424 - mse: 0.1424 - mae: 0.2150 - val_loss: 0.1109 - val_mse: 0.1109 - val_mae: 0.2051\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1384 - mse: 0.1384 - mae: 0.2121 - val_loss: 0.1100 - val_mse: 0.1100 - val_mae: 0.2037\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.1338 - mse: 0.1338 - mae: 0.2102 - val_loss: 0.1095 - val_mse: 0.1095 - val_mae: 0.2010\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.1302 - mse: 0.1302 - mae: 0.2073 - val_loss: 0.1081 - val_mse: 0.1081 - val_mae: 0.1997\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.1269 - mse: 0.1269 - mae: 0.2069 - val_loss: 0.1053 - val_mse: 0.1053 - val_mae: 0.1992\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.1245 - mse: 0.1245 - mae: 0.2036 - val_loss: 0.1060 - val_mse: 0.1060 - val_mae: 0.1993\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1196 - mse: 0.1196 - mae: 0.2017 - val_loss: 0.1036 - val_mse: 0.1036 - val_mae: 0.1983\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1150 - mse: 0.1150 - mae: 0.1996 - val_loss: 0.1021 - val_mse: 0.1021 - val_mae: 0.1972\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1107 - mse: 0.1107 - mae: 0.1966 - val_loss: 0.0998 - val_mse: 0.0998 - val_mae: 0.1964\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1070 - mse: 0.1070 - mae: 0.1946 - val_loss: 0.0990 - val_mse: 0.0990 - val_mae: 0.1963\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.1042 - mse: 0.1042 - mae: 0.1930 - val_loss: 0.0992 - val_mse: 0.0992 - val_mae: 0.1940\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.0995 - mse: 0.0995 - mae: 0.1913 - val_loss: 0.0972 - val_mse: 0.0972 - val_mae: 0.1930\n",
            "Epoch 17/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.0969 - mse: 0.0969 - mae: 0.1889 - val_loss: 0.0973 - val_mse: 0.0973 - val_mae: 0.1924\n",
            "Epoch 18/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.0918 - mse: 0.0918 - mae: 0.1859 - val_loss: 0.0985 - val_mse: 0.0985 - val_mae: 0.1938\n",
            "Epoch 19/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.0923 - mse: 0.0923 - mae: 0.1852 - val_loss: 0.0979 - val_mse: 0.0979 - val_mae: 0.1931\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.8621 - mse: 0.8621 - mae: 0.6530 - val_loss: 0.3820 - val_mse: 0.3820 - val_mae: 0.4632\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3695 - mse: 0.3695 - mae: 0.4503 - val_loss: 0.3328 - val_mse: 0.3328 - val_mae: 0.4335\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.3279 - mse: 0.3279 - mae: 0.4244 - val_loss: 0.3178 - val_mse: 0.3178 - val_mae: 0.4229\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3057 - mse: 0.3057 - mae: 0.4107 - val_loss: 0.3081 - val_mse: 0.3081 - val_mae: 0.4159\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2839 - mse: 0.2839 - mae: 0.3967 - val_loss: 0.3021 - val_mse: 0.3021 - val_mae: 0.4104\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2684 - mse: 0.2684 - mae: 0.3872 - val_loss: 0.2957 - val_mse: 0.2957 - val_mae: 0.4057\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.2552 - mse: 0.2552 - mae: 0.3772 - val_loss: 0.2929 - val_mse: 0.2929 - val_mae: 0.4038\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2466 - mse: 0.2466 - mae: 0.3711 - val_loss: 0.2913 - val_mse: 0.2913 - val_mae: 0.4034\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2312 - mse: 0.2312 - mae: 0.3626 - val_loss: 0.2895 - val_mse: 0.2895 - val_mae: 0.4035\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.2179 - mse: 0.2179 - mae: 0.3515 - val_loss: 0.2871 - val_mse: 0.2871 - val_mae: 0.4012\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2135 - mse: 0.2135 - mae: 0.3481 - val_loss: 0.2889 - val_mse: 0.2889 - val_mae: 0.4011\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2032 - mse: 0.2032 - mae: 0.3417 - val_loss: 0.2871 - val_mse: 0.2871 - val_mae: 0.4009\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1928 - mse: 0.1928 - mae: 0.3337 - val_loss: 0.2889 - val_mse: 0.2889 - val_mae: 0.4006\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1878 - mse: 0.1878 - mae: 0.3298 - val_loss: 0.2880 - val_mse: 0.2880 - val_mae: 0.4005\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1824 - mse: 0.1824 - mae: 0.3238 - val_loss: 0.2880 - val_mse: 0.2880 - val_mae: 0.4000\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.6868 - mse: 0.6868 - mae: 0.5982 - val_loss: 0.3020 - val_mse: 0.3020 - val_mae: 0.4139\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2986 - mse: 0.2986 - mae: 0.4123 - val_loss: 0.2672 - val_mse: 0.2672 - val_mae: 0.3909\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2623 - mse: 0.2623 - mae: 0.3875 - val_loss: 0.2569 - val_mse: 0.2569 - val_mae: 0.3824\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.2457 - mse: 0.2457 - mae: 0.3758 - val_loss: 0.2527 - val_mse: 0.2527 - val_mae: 0.3782\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2334 - mse: 0.2334 - mae: 0.3650 - val_loss: 0.2460 - val_mse: 0.2460 - val_mae: 0.3697\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2186 - mse: 0.2186 - mae: 0.3520 - val_loss: 0.2458 - val_mse: 0.2458 - val_mae: 0.3688\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2116 - mse: 0.2116 - mae: 0.3468 - val_loss: 0.2416 - val_mse: 0.2416 - val_mae: 0.3651\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.2008 - mse: 0.2008 - mae: 0.3388 - val_loss: 0.2423 - val_mse: 0.2423 - val_mae: 0.3651\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1953 - mse: 0.1953 - mae: 0.3340 - val_loss: 0.2408 - val_mse: 0.2408 - val_mae: 0.3637\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.1873 - mse: 0.1873 - mae: 0.3287 - val_loss: 0.2395 - val_mse: 0.2395 - val_mae: 0.3632\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.1801 - mse: 0.1801 - mae: 0.3216 - val_loss: 0.2395 - val_mse: 0.2395 - val_mae: 0.3636\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1740 - mse: 0.1740 - mae: 0.3164 - val_loss: 0.2390 - val_mse: 0.2390 - val_mae: 0.3630\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.1685 - mse: 0.1685 - mae: 0.3121 - val_loss: 0.2409 - val_mse: 0.2409 - val_mae: 0.3630\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1648 - mse: 0.1648 - mae: 0.3079 - val_loss: 0.2407 - val_mse: 0.2407 - val_mae: 0.3639\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1609 - mse: 0.1609 - mae: 0.3050 - val_loss: 0.2417 - val_mse: 0.2417 - val_mae: 0.3641\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.4466 - mse: 0.4466 - mae: 0.4066 - val_loss: 0.3428 - val_mse: 0.3428 - val_mae: 0.3408\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.2270 - mse: 0.2270 - mae: 0.3006 - val_loss: 0.1709 - val_mse: 0.1709 - val_mae: 0.2672\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1551 - mse: 0.1551 - mae: 0.2596 - val_loss: 0.1456 - val_mse: 0.1456 - val_mae: 0.2490\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.1354 - mse: 0.1354 - mae: 0.2454 - val_loss: 0.1374 - val_mse: 0.1374 - val_mae: 0.2417\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1264 - mse: 0.1264 - mae: 0.2365 - val_loss: 0.1317 - val_mse: 0.1317 - val_mae: 0.2363\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1180 - mse: 0.1180 - mae: 0.2290 - val_loss: 0.1298 - val_mse: 0.1298 - val_mae: 0.2331\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1112 - mse: 0.1112 - mae: 0.2237 - val_loss: 0.1308 - val_mse: 0.1308 - val_mae: 0.2339\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1071 - mse: 0.1071 - mae: 0.2203 - val_loss: 0.1303 - val_mse: 0.1303 - val_mae: 0.2306\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.1008 - mse: 0.1008 - mae: 0.2145 - val_loss: 0.1264 - val_mse: 0.1264 - val_mae: 0.2296\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.0959 - mse: 0.0959 - mae: 0.2108 - val_loss: 0.1300 - val_mse: 0.1300 - val_mae: 0.2286\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.0939 - mse: 0.0939 - mae: 0.2086 - val_loss: 0.1256 - val_mse: 0.1256 - val_mae: 0.2278\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 0.0888 - mse: 0.0888 - mae: 0.2045 - val_loss: 0.1266 - val_mse: 0.1266 - val_mae: 0.2263\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.0862 - mse: 0.0862 - mae: 0.2012 - val_loss: 0.1244 - val_mse: 0.1244 - val_mae: 0.2264\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.0822 - mse: 0.0822 - mae: 0.1987 - val_loss: 0.1250 - val_mse: 0.1250 - val_mae: 0.2254\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.0802 - mse: 0.0802 - mae: 0.1959 - val_loss: 0.1250 - val_mse: 0.1250 - val_mae: 0.2260\n",
            "Epoch 16/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.0768 - mse: 0.0768 - mae: 0.1936 - val_loss: 0.1271 - val_mse: 0.1271 - val_mae: 0.2258\n",
            "Epoch 1/50\n",
            "55/55 [==============================] - 1s 10ms/step - loss: 1.7782 - mse: 1.7782 - mae: 1.0009 - val_loss: 0.4477 - val_mse: 0.4477 - val_mae: 0.5364\n",
            "Epoch 2/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.5384 - mse: 0.5384 - mae: 0.5846 - val_loss: 0.4013 - val_mse: 0.4013 - val_mae: 0.5072\n",
            "Epoch 3/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.4885 - mse: 0.4885 - mae: 0.5581 - val_loss: 0.3870 - val_mse: 0.3870 - val_mae: 0.4988\n",
            "Epoch 4/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4567 - mse: 0.4567 - mae: 0.5390 - val_loss: 0.3754 - val_mse: 0.3754 - val_mae: 0.4895\n",
            "Epoch 5/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4349 - mse: 0.4349 - mae: 0.5263 - val_loss: 0.3642 - val_mse: 0.3642 - val_mae: 0.4824\n",
            "Epoch 6/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.4101 - mse: 0.4101 - mae: 0.5108 - val_loss: 0.3573 - val_mse: 0.3573 - val_mae: 0.4764\n",
            "Epoch 7/50\n",
            "55/55 [==============================] - 0s 9ms/step - loss: 0.3882 - mse: 0.3882 - mae: 0.4958 - val_loss: 0.3555 - val_mse: 0.3555 - val_mae: 0.4757\n",
            "Epoch 8/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3793 - mse: 0.3793 - mae: 0.4909 - val_loss: 0.3490 - val_mse: 0.3490 - val_mae: 0.4696\n",
            "Epoch 9/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3670 - mse: 0.3670 - mae: 0.4835 - val_loss: 0.3472 - val_mse: 0.3472 - val_mae: 0.4687\n",
            "Epoch 10/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3534 - mse: 0.3534 - mae: 0.4735 - val_loss: 0.3487 - val_mse: 0.3487 - val_mae: 0.4702\n",
            "Epoch 11/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3459 - mse: 0.3459 - mae: 0.4677 - val_loss: 0.3427 - val_mse: 0.3427 - val_mae: 0.4658\n",
            "Epoch 12/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3390 - mse: 0.3390 - mae: 0.4640 - val_loss: 0.3426 - val_mse: 0.3426 - val_mae: 0.4656\n",
            "Epoch 13/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3282 - mse: 0.3282 - mae: 0.4560 - val_loss: 0.3427 - val_mse: 0.3427 - val_mae: 0.4652\n",
            "Epoch 14/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3177 - mse: 0.3177 - mae: 0.4492 - val_loss: 0.3439 - val_mse: 0.3439 - val_mae: 0.4664\n",
            "Epoch 15/50\n",
            "55/55 [==============================] - 1s 9ms/step - loss: 0.3100 - mse: 0.3100 - mae: 0.4433 - val_loss: 0.3431 - val_mse: 0.3431 - val_mae: 0.4662\n",
            "0.40623758124472237\n",
            "0.40608554982164885\n",
            "0.3916939717220335\n",
            "0.3452288188189842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJ8U04_GWa-m",
        "colab_type": "text"
      },
      "source": [
        "## Training Loss plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR1D8mHYFrfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "7f2a6e41-fd51-463b-85a9-f64f134f49e2"
      },
      "source": [
        "# Loss plot\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Accuracy plot\n",
        "plt.clf()\n",
        "acc_values = history_dict['mse']\n",
        "val_acc_values = history_dict['val_mse']\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXQhJIBDWYeV",
        "colab_type": "text"
      },
      "source": [
        "## Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trbSLp9_PQmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "outputId": "083fbf2d-f773-4942-f93b-404010ca19f2"
      },
      "source": [
        "algs = [\"Linear Regression\", \"Ridge Regression\", \"Gradient Boosting Regressor\", \"Neural Network\"]\n",
        "\n",
        "for i, s in enumerate(scores):\n",
        "  print(\"Algorithm:\", algs[i])\n",
        "  print(\"Mean Squared Error: \"  , s[2])\n",
        "  print(\"Individual MSE scores: \") \n",
        "  print(s[3])\n",
        "  print(\"Mean Average Error: \" , s[0])\n",
        "  print(\"Individual MAE scores: \") \n",
        "  print(s[1])\n",
        "  print(\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Algorithm: Linear Regression\n",
            "Mean Squared Error:  0.5369598589840622\n",
            "Individual MSE scores: \n",
            "[0.6295360433159926, 0.4012604652135086, 0.5931463125225931, 0.5438411742805315, 0.4089642146451524, 0.6450109439265954]\n",
            "Mean Average Error:  0.40623758124472237\n",
            "Individual MAE scores: \n",
            "[0.4955060913099205, 0.2728733188948354, 0.45321892481457304, 0.41374304508500964, 0.2897618528512396, 0.5123222545127564]\n",
            "\n",
            "\n",
            "\n",
            "Algorithm: Ridge Regression\n",
            "Mean Squared Error:  0.5369349620082696\n",
            "Individual MSE scores: \n",
            "[0.6295041809708599, 0.401332043962472, 0.5930405460802377, 0.5438331974923788, 0.40886590792591937, 0.64503389561775]\n",
            "Mean Average Error:  0.40608554982164885\n",
            "Individual MAE scores: \n",
            "[0.49549440914939485, 0.2725729582835801, 0.45305227785956137, 0.4136683166190921, 0.2894023627819005, 0.512322974236364]\n",
            "\n",
            "\n",
            "\n",
            "Algorithm: Gradient Boosting Regressor\n",
            "Mean Squared Error:  0.5321245094627232\n",
            "Individual MSE scores: \n",
            "[0.6314117950587989, 0.3803651143000292, 0.5940404668724854, 0.5458464039147981, 0.39344885451942196, 0.6476344221108052]\n",
            "Mean Average Error:  0.3916939717220335\n",
            "Individual MAE scores: \n",
            "[0.494207643398233, 0.2269546313573126, 0.4487351318991862, 0.4095856709345615, 0.257999890990745, 0.5126808617521629]\n",
            "\n",
            "\n",
            "\n",
            "Algorithm: Neural Network\n",
            "Mean Squared Error:  0.4701983807014762\n",
            "Individual MSE scores: \n",
            "[0.554699530830194, 0.3211554571120114, 0.515207702506459, 0.4917272747364908, 0.34228389943922866, 0.5961164195844733]\n",
            "Mean Average Error:  0.3452288188189842\n",
            "Individual MAE scores: \n",
            "[0.4278143272297244, 0.19696471567065812, 0.3858782276908481, 0.363253545631366, 0.22270222518908092, 0.47475987150222754]\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}